\subsection{Diagnosis Extraction
Pipeline}\label{diagnosis-extraction-pipeline}

This document briefly describes a pipeline to extract diagnosis out of a
medical report along with a (rough) estimate on its reliability
(confirmed, suspected, excluded).

\subsubsection{Approach}\label{approach}

The current implementation is mainly based on keyword matching and is
hence very basic. An initial evaluation shows that the diagnosis are
extracted well, however, the reliability of the diagnosis are not
detected very reliably as the language around suspected or excluded
cases can be involved. Because of way the pipeline is currently
implemented, there is a bias towards `confirmed' diagnosis, i.e the
pipeline may label a diagnosis as \texttt{confirmed} whereas the actual
diagnosis was merely a suspection or even an exclusion.

\subsubsection{Pipeline Overview}\label{pipeline-overview}

The pipeline is based on the same framework as the deidentification
pipeline and hence shares many commonalities.

The input is the same as for the \texttt{annotation} tool i.e.~reports
out of KISIM either directly from a database or already imported as GATE
documents.

The pipeline generates for every diagnosis the following output:

\begin{itemize}
\tightlist
\item
  document ID/report ID
\item
  annotation text found related to diagnosis (mainly for debugging)
\item
  code (ICD-10)
\item
  reliability of diagnosis: confirmed, suspected, excluded
\end{itemize}

Note, that per report several diagnosis may be extracted. Furthermore,
the reliabilities may be conflicting, that is, in a report there may be
the same diagnosis twice with different reliabilities. Depending on the
use case, the downstream system need to resolve this ``conflict''.

These fields can be written back to a database table and/or written to a
text file for further analysis in pandas/excel.

\subsubsection{Configuration}\label{configuration}

\paragraph{Database Configuraiton}\label{database-configuraiton}

The configuration related for reading and writing into the database are
the same as with the deidentification pipeline. There are just a few
more configuration keys related to the naming of the fields generated by
the diagnosis extraction pipeline:

\begin{verbatim}
annotationtext_field_name=annotationtext
reliability_field_name=reliability
code_field_name=code
\end{verbatim}

These properties can be changed to match the destination table schema.
The same keys should then be used in the \texttt{dest\_columns}
property.

For example:

\begin{verbatim}
dest_columns=reportnr,fcode,dat,fallnr,annotationtext,code,reliability
\end{verbatim}

\paragraph{Pipeline Configuration}\label{pipeline-configuration}

Many aspects of the pipeline can be tweaked by editing text files.

\subparagraph{Keywords Configuration}\label{keywords-configuration}

For every ICD-10 code to be extracted there needs to be a few
keywords/names for the condition. The keyword configuration file is a
text file where a row corresponds to one ICD-10 code. The fields are
separated by \texttt{;} and constituting the following:

\begin{itemize}
\tightlist
\item
  ICD-10 code, for example \texttt{G35};
\item
  keywords separated by \texttt{,}, for example
  \texttt{Multiple\ Sklerosis,Encephalitis\ disseminata}
\item
  blacklist paths: paths in the document structure which should not be
  considered to search for the keyword:
  e.g.~\texttt{Header,Fragestellung} (see also
  \texttt{Paths\ in\ Field\ Tree} in \texttt{components.md})
\end{itemize}

\subparagraph{Reliability Context
Configuration}\label{reliability-context-configuration}

In order to assess the reliability of a diagnosis the `reliability
context' of a diagnosis is determined. This is done in a very crude way
by looking for keywords within the neighborhood of a diagnosis keyword.
For instance \texttt{ausgeschlossen} somewhere close after a diagnosis
term like \texttt{Multiple\ Sklerose} could mean that the diagnosis is
excluded.

These keywords can be configured the in reliability context
configuration file. This is a textfile with one keyword a line, where
the fields are separated by \texttt{;}. The fields are as follows

\begin{itemize}
\tightlist
\item
  context keyword, e.g.~\texttt{ausgeschlossen}
\item
  context name: \texttt{ExclusionContext} or \texttt{SuspectionContext}
\item
  left extend: number of tokens from the context keyword to the left,
  the context is valid
\item
  right extend: number of tokens from the context keyword to the right
\end{itemize}

\subsubsection{Invocation}\label{invocation}

The entry point of the pipeline is the
\texttt{org.ratschlab.structuring.DiagnosisExtractionCmd} class. It has
the following usage (note, that currently not all options are
implemented).

\begin{verbatim}
 Usage: <main class> [--json-input] [--xml-input]
                     [--doc-id-filter=<docIdFilterPath>]
                     [--doc-type-filter=<docTypeFilterPath>]
                     [--max-docs=<maxDocs>]
                     [--output-corpus-dir=<outputCorpusDir>]
                     [--skip-docs=<skipDocs>] -c=<pipelineConfigFile>
                     [-d=<databaseConfigPath>] [-i=<corpusInputDir>]
                     [-o=<outputFile>] [-t=<threads>]
       --doc-id-filter=<docIdFilterPath>
                              Path to file id list to consider
       --doc-type-filter=<docTypeFilterPath>
                              Path to file type list to consider
       --json-input           Assumes input dir consists of json files, one per
                                report (testing purposes)
       --max-docs=<maxDocs>   Maximum number of docs to process
       --output-corpus-dir=<outputCorpusDir>
                              Output GATE Corpus Dir
       --skip-docs=<skipDocs> Skipping number of docs (useful to just work on a slice
                                of the corpus)
       --xml-input            Assumes input dir consists of xml files, one per report
                                (testing purposes)
   -c=<pipelineConfigFile>    Config file
   -d=<databaseConfigPath>    DB config path
   -i=<corpusInputDir>        Input corpus dir
   -o=<outputFile>            Output Txt File
   -t=<threads>               Number of threads
\end{verbatim}

\subsubsection{Pipeline Description}\label{pipeline-description}

The pipeline executes the following steps for every document:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  tokenization of the import report
\item
  diagnosis keywords are annotated
\item
  reliability contexts are annotated
\item
  JAPE rules are run to

  \begin{itemize}
  \tightlist
  \item
    determine the reliability of a diagnosis by either checking whether
    it is within some reliability context or whether it matches a
    certain language pattern (e.g.~\texttt{Verdacht\ auf} \ldots)
  \item
    Removing some false positives like
    \texttt{some\_diagnosis\ Sprechstunde} or
    \texttt{some\_diagnosis\ Abklaerung}
  \end{itemize}
\item
  Consolidate diagnosis anntoations: * adding \texttt{confirmed}
  reliability as default, if no other reliability could be determined *
  removing duplicates
\item
  Writing to file and/or database
\end{enumerate}
